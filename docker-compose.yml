version: "3"
services:
    find_miner:
        restart: always
        container_name: "find_miner"
        #platform: linux/arm64/v8
        build: ./
        network_mode: "host"
        #privileged: true
        #extra_hosts:
        #    ai-rabbit: 192.168.1.10
        #   mariadb_tm: 192.168.1.10
        #   videoserver: 192.168.1.10
        #   redis_tm: 192.168.1.10
        volumes:
            - ./app:/code/app
            - ./data/minerImages:/data/minerImages
            - ./data/journal:/data/journal
            - ./data/config:/data/config
            - /var/run/docker.sock:/var/run/docker.sock
        #ports:
            #- "80:80"
        #environment:
        #- FLASK_APP=main.py
        #- FLASK_DEBUG=1
        #- "RUN=flask run --host=0.0.0.0 --port=80"
        # - PASS=0011
    nvds:
        restart: always
        build: ./video
        runtime: nvidia
        stdin_open: true # docker run -i
        tty: true        # docker run -t
        network_mode: "host" # for arm64
        privileged: true
        environment:    
            #- DISPLAY=:0
            - TAG=gmc1
            - PLATFORM=arm64
            #- PLATFORM=x86_64
            - DS_REL_PKG=deepstream_sdk_v5.1.0_arm64.tbz2
            #- DS_REL_PKG=deepstream_sdk_v5.1.0_x86_64.tbz2
            - DS_REL_PKG_DIR=deepstream_sdk_v5.1.0_arm64
            #- DS_REL_PKG_DIR=deepstream_sdk_v5.1.0_x86_64
            - DS_VERSION=5.1.0
            - PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
            - CUDA_VERSION=10.2
            #- CUDA_VERSION=11.1.1
            - LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:/usr/lib/i386-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
            - NVIDIA_VISIBLE_DEVICES=all
            - NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics,compat32,utility,video
            - NVIDIA_REQUIRE_CUDA=cuda>=10.2 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450,driver<451
            # - NVIDIA_REQUIRE_CUDA=cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450,driver<451
            - NCCL_VERSION=2.8.3
            - LIBRARY_PATH=/usr/local/cuda/lib64/stubs
            - RTSPINPUT=rtsp://192.168.1.13:554/substream
            - ARCH=arm64
            # - ARCH=x86_64
            - IPADDR=localhost
            - OUTPUT_WIDHT=720
            - OUTPUT_HIGHT=576
            - RTSPOUTPATH=/ds-test
            - RTSPOUTPUTPORTNUM=8554
        volumes:
            - ./video/deepstream_python_apps/:/opt/nvidia/deepstream/deepstream/sources/deepstream_python_apps
            #- ./data:/data
            - ./data/config/config.txt:/config.txt
            - /tmp/.X11-unix/:/tmp/.X11-unix
            - ./video/cfg_amqp.txt:/cfg_amqp.txt
        # ports:
          # - "8554:8554"
          # docker exec -it video_nvds_1 bash
        command: bash -c "cd /opt/nvidia/deepstream/deepstream-5.1/sources/deepstream_python_apps/apps/deepstream-test1/ && python3 /opt/nvidia/deepstream/deepstream-5.1/sources/deepstream_python_apps/apps/deepstream-test1/deepstream_test_1.py --cfg-file /cfg_amqp.txt -i rtsp://192.168.11.33:555/mainstream -p /opt/nvidia/deepstream/deepstream-5.1/lib/libnvds_amqp_proto.so --conn-str '0.0.0.0;5672;prog'"
    # ----------------------- RabbitMQ -----------------------
    messageq:
      image: rabbitmq:3-management
      restart: always
      container_name: ai-rabbit
      ports:
          - "8080:15672"
          - "5672:5672"
      environment:
          - RABBITMQ_DEFAULT_USER=prog
          - RABBITMQ_DEFAULT_PASS=0011
      # command: "rabbitmqctl add_user prog 0011"

